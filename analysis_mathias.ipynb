{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Diagnostics for Simulated Investment Panels\n",
    "\n",
    "This notebook expands the diagnostics into a **standard analysis pipeline** for the model output.\n",
    "\n",
    "## What statistics matter most in this class of models?\n",
    "\n",
    "### 1) Investment behavior\n",
    "- **Mean/median investment rate (`I_total / K`)**: central measure of capital adjustment intensity.\n",
    "- **Dispersion of investment rates** (std, IQR, p10/p90): captures heterogeneity and lumpy adjustment.\n",
    "- **Inaction rate** (`|I_total|` near zero): key moment under fixed or non-convex adjustment costs.\n",
    "- **Positive vs negative investment shares**: identifies asymmetry and irreversibility/frictions.\n",
    "- **Semi-annual timing decomposition** (`I` vs `Delta_I`): measures how much adjustment happens initially vs after mid-year information.\n",
    "\n",
    "### 2) State dependence\n",
    "- **Investment by demand state** (`log_D`) and volatility state (`log_sigma`): tests policy function monotonicity and uncertainty effects.\n",
    "- **Regime contrasts** (low vs high volatility quantiles): reduced-form uncertainty-investment relationship.\n",
    "\n",
    "### 3) Dynamics\n",
    "- **Persistence/autocorrelation of investment rates**: serial dependence and gradual adjustment.\n",
    "- **Year profiles of average investment/profit/capital**: transition dynamics and stationarity checks.\n",
    "\n",
    "### 4) Cross-sectional heterogeneity\n",
    "- **Between-firm dispersion** (distribution of firm-level means): persistent heterogeneity across firms.\n",
    "- **Within-firm volatility**: cyclical variation and sensitivity to shocks.\n",
    "\n",
    "### 5) Economic outcomes\n",
    "- **Profit levels and dispersion**.\n",
    "- **Capital distribution moments**.\n",
    "- **Correlation of investment with demand and volatility**.\n",
    "\n",
    "The cells below implement all these diagnostics for one or multiple simulation outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q pandas numpy matplotlib pyfixest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "pd.options.display.float_format = \"{:.4f}\".format\n",
    "\n",
    "# Update this path if your simulation CSVs are elsewhere.\n",
    "folder_path = \"../output/simulations\"\n",
    "pattern = \"panel_data*.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load panels\n",
    "The loader searches for `panel_data*.csv` and creates a dictionary `{scenario_name: DataFrame}`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_panels(folder_path, pattern=\"panel_data*.csv\"):\n",
    "    files = sorted(glob.glob(os.path.join(folder_path, pattern)))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(\n",
    "            f\"No files matching '{pattern}' were found in {folder_path}. \"\n",
    "            \"Run simulation first or update `folder_path`.\"\n",
    "        )\n",
    "\n",
    "    panels = {}\n",
    "    for path in files:\n",
    "        name = os.path.splitext(os.path.basename(path))[0]\n",
    "        df = pd.read_csv(path)\n",
    "\n",
    "        # Safety: reconstruct investment rate if absent\n",
    "        if \"I_rate\" not in df.columns and {\"I_total\", \"K\"}.issubset(df.columns):\n",
    "            df[\"I_rate\"] = df[\"I_total\"] / df[\"K\"].replace(0, np.nan)\n",
    "\n",
    "        panels[name] = df\n",
    "\n",
    "    return panels\n",
    "\n",
    "panels = load_panels(folder_path, pattern=pattern)\n",
    "print(f\"Loaded {len(panels)} scenario(s): {list(panels.keys())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core diagnostic statistics\n",
    "This block computes a rich set of moments for each scenario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocorr_by_firm(df, var, lags=(1, 2)):\n",
    "    out = {}\n",
    "    grouped = df.sort_values([\"firm_id\", \"year\"]).groupby(\"firm_id\")\n",
    "    for lag in lags:\n",
    "        vals = []\n",
    "        for _, g in grouped:\n",
    "            x = g[var]\n",
    "            if len(x) > lag and x.std() > 0:\n",
    "                vals.append(x.autocorr(lag=lag))\n",
    "        out[f\"{var}_ac{lag}_mean\"] = np.nanmean(vals) if vals else np.nan\n",
    "    return out\n",
    "\n",
    "\n",
    "def scenario_diagnostics(df, near_zero=1e-6):\n",
    "    stats = {}\n",
    "\n",
    "    # Basic panel size\n",
    "    stats[\"n_obs\"] = len(df)\n",
    "    stats[\"n_firms\"] = df[\"firm_id\"].nunique()\n",
    "    stats[\"T\"] = df.groupby(\"firm_id\")[\"year\"].max().median()\n",
    "\n",
    "    # Investment moments\n",
    "    i = df[\"I_rate\"]\n",
    "    stats[\"I_rate_mean\"] = i.mean()\n",
    "    stats[\"I_rate_median\"] = i.median()\n",
    "    stats[\"I_rate_std\"] = i.std()\n",
    "    stats[\"I_rate_p10\"] = i.quantile(0.10)\n",
    "    stats[\"I_rate_p90\"] = i.quantile(0.90)\n",
    "    stats[\"I_rate_iqr\"] = i.quantile(0.75) - i.quantile(0.25)\n",
    "\n",
    "    # Lumpy adjustment / inaction / sign asymmetry\n",
    "    total_i = df[\"I_total\"]\n",
    "    stats[\"inaction_rate\"] = (total_i.abs() <= near_zero).mean()\n",
    "    stats[\"positive_invest_share\"] = (total_i > near_zero).mean()\n",
    "    stats[\"negative_invest_share\"] = (total_i < -near_zero).mean()\n",
    "\n",
    "    # Timing decomposition\n",
    "    abs_i = df[\"I\"].abs().sum()\n",
    "    abs_di = df[\"Delta_I\"].abs().sum()\n",
    "    denom = abs_i + abs_di\n",
    "    stats[\"share_initial_abs_adjustment\"] = abs_i / denom if denom > 0 else np.nan\n",
    "    stats[\"share_midyear_abs_adjustment\"] = abs_di / denom if denom > 0 else np.nan\n",
    "\n",
    "    # State dependence and reduced-form associations\n",
    "    stats[\"corr_Irate_logD\"] = df[[\"I_rate\", \"log_D\"]].corr().iloc[0, 1]\n",
    "    stats[\"corr_Irate_logSigma\"] = df[[\"I_rate\", \"log_sigma\"]].corr().iloc[0, 1]\n",
    "\n",
    "    # High- vs low-volatility regime gap\n",
    "    q25, q75 = df[\"log_sigma\"].quantile([0.25, 0.75])\n",
    "    low = df.loc[df[\"log_sigma\"] <= q25, \"I_rate\"].mean()\n",
    "    high = df.loc[df[\"log_sigma\"] >= q75, \"I_rate\"].mean()\n",
    "    stats[\"Irate_low_vol\"] = low\n",
    "    stats[\"Irate_high_vol\"] = high\n",
    "    stats[\"Irate_high_minus_low_vol\"] = high - low\n",
    "\n",
    "    # Capital and profit moments\n",
    "    stats[\"K_mean\"] = df[\"K\"].mean()\n",
    "    stats[\"K_std\"] = df[\"K\"].std()\n",
    "    stats[\"profit_mean\"] = df[\"profit\"].mean()\n",
    "    stats[\"profit_std\"] = df[\"profit\"].std()\n",
    "\n",
    "    # Dynamics: autocorrelation (averaged over firms)\n",
    "    stats.update(autocorr_by_firm(df, \"I_rate\", lags=(1, 2)))\n",
    "    stats.update(autocorr_by_firm(df, \"profit\", lags=(1, 2)))\n",
    "\n",
    "    # Heterogeneity: distribution of firm means and within-firm volatility\n",
    "    firm_mean = df.groupby(\"firm_id\")[\"I_rate\"].mean()\n",
    "    firm_std = df.groupby(\"firm_id\")[\"I_rate\"].std()\n",
    "    stats[\"between_firm_std_of_mean_Irate\"] = firm_mean.std()\n",
    "    stats[\"mean_within_firm_std_Irate\"] = firm_std.mean()\n",
    "\n",
    "    return stats\n",
    "\n",
    "\n",
    "def diagnostics_table(panels):\n",
    "    rows = []\n",
    "    for scenario, df in panels.items():\n",
    "        row = {\"scenario\": scenario}\n",
    "        row.update(scenario_diagnostics(df))\n",
    "        rows.append(row)\n",
    "    return pd.DataFrame(rows).set_index(\"scenario\").sort_index()\n",
    "\n",
    "summary = diagnostics_table(panels)\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretty summary (selected headline moments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headline_cols = [\n",
    "    \"n_firms\", \"T\", \"I_rate_mean\", \"I_rate_std\", \"inaction_rate\",\n",
    "    \"positive_invest_share\", \"negative_invest_share\",\n",
    "    \"share_initial_abs_adjustment\", \"share_midyear_abs_adjustment\",\n",
    "    \"Irate_high_minus_low_vol\", \"I_rate_ac1_mean\", \"profit_ac1_mean\"\n",
    "]\n",
    "\n",
    "summary[headline_cols].sort_values(\"I_rate_mean\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual diagnostics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_investment_rate_distribution(panels, bins=60):\n",
    "    n = len(panels)\n",
    "    fig, axes = plt.subplots(n, 1, figsize=(10, 3.2 * n), squeeze=False)\n",
    "    for ax, (scenario, df) in zip(axes.flatten(), panels.items()):\n",
    "        ax.hist(df[\"I_rate\"].dropna(), bins=bins, alpha=0.85)\n",
    "        ax.axvline(df[\"I_rate\"].mean(), linestyle=\"--\", linewidth=1.5, label=\"mean\")\n",
    "        ax.set_title(f\"Investment rate distribution \u2014 {scenario}\")\n",
    "        ax.set_xlabel(\"I_rate\")\n",
    "        ax.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "plot_investment_rate_distribution(panels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_profiles(panels):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 4))\n",
    "    for scenario, df in panels.items():\n",
    "        by_year = df.groupby(\"year\").agg(\n",
    "            I_rate_mean=(\"I_rate\", \"mean\"),\n",
    "            profit_mean=(\"profit\", \"mean\"),\n",
    "            K_mean=(\"K\", \"mean\")\n",
    "        )\n",
    "        axes[0].plot(by_year.index, by_year[\"I_rate_mean\"], label=scenario)\n",
    "        axes[1].plot(by_year.index, by_year[\"profit_mean\"], label=scenario)\n",
    "        axes[2].plot(by_year.index, by_year[\"K_mean\"], label=scenario)\n",
    "\n",
    "    axes[0].set_title(\"Mean investment rate over time\")\n",
    "    axes[1].set_title(\"Mean profit over time\")\n",
    "    axes[2].set_title(\"Mean capital over time\")\n",
    "    for ax in axes:\n",
    "        ax.set_xlabel(\"Year\")\n",
    "        ax.legend(fontsize=8)\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "plot_time_profiles(panels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binned_state_dependence(df, state_col, target_col=\"I_rate\", n_bins=12):\n",
    "    x = df[state_col]\n",
    "    bins = pd.qcut(x, q=n_bins, duplicates=\"drop\")\n",
    "    out = df.groupby(bins, observed=False)[target_col].mean().reset_index()\n",
    "    out[\"mid\"] = out[state_col].apply(lambda iv: (iv.left + iv.right) / 2)\n",
    "    return out[[\"mid\", target_col]]\n",
    "\n",
    "\n",
    "def plot_state_dependence(panels):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "    for scenario, df in panels.items():\n",
    "        b1 = binned_state_dependence(df, \"log_D\", \"I_rate\")\n",
    "        b2 = binned_state_dependence(df, \"log_sigma\", \"I_rate\")\n",
    "\n",
    "        axes[0].plot(b1[\"mid\"], b1[\"I_rate\"], marker=\"o\", label=scenario)\n",
    "        axes[1].plot(b2[\"mid\"], b2[\"I_rate\"], marker=\"o\", label=scenario)\n",
    "\n",
    "    axes[0].set_title(\"Investment vs demand state (binned)\")\n",
    "    axes[0].set_xlabel(\"log_D bin midpoint\")\n",
    "    axes[0].set_ylabel(\"Mean I_rate\")\n",
    "\n",
    "    axes[1].set_title(\"Investment vs volatility state (binned)\")\n",
    "    axes[1].set_xlabel(\"log_sigma bin midpoint\")\n",
    "    axes[1].set_ylabel(\"Mean I_rate\")\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.legend(fontsize=8)\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "plot_state_dependence(panels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_adjustment_timing(panels):\n",
    "    scenarios = list(panels.keys())\n",
    "    initial = []\n",
    "    midyear = []\n",
    "\n",
    "    for _, df in panels.items():\n",
    "        abs_i = df[\"I\"].abs().sum()\n",
    "        abs_di = df[\"Delta_I\"].abs().sum()\n",
    "        total = abs_i + abs_di\n",
    "        initial.append(abs_i / total if total > 0 else np.nan)\n",
    "        midyear.append(abs_di / total if total > 0 else np.nan)\n",
    "\n",
    "    x = np.arange(len(scenarios))\n",
    "    w = 0.37\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 4.5))\n",
    "    ax.bar(x - w/2, initial, width=w, label=\"Initial I share\")\n",
    "    ax.bar(x + w/2, midyear, width=w, label=\"Mid-year \u0394I share\")\n",
    "\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(scenarios, rotation=25, ha=\"right\")\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_title(\"Absolute adjustment timing decomposition\")\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "plot_adjustment_timing(panels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: keep simple pairwise scenario checks\n",
    "These preserve your earlier quick tests but now fit into the expanded workflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_pair_plot(panels, s1, s2, firm_id=1):\n",
    "    if s1 not in panels or s2 not in panels:\n",
    "        print(f\"Skipping: {s1} or {s2} not found.\")\n",
    "        return\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9, 4))\n",
    "    panels[s1].query(\"firm_id == @firm_id\").plot(x=\"year\", y=\"I_total\", ax=ax, label=f\"{s1}\")\n",
    "    panels[s2].query(\"firm_id == @firm_id\").plot(x=\"year\", y=\"I_total\", ax=ax, label=f\"{s2}\")\n",
    "    ax.set_title(f\"Firm {firm_id}: total investment comparison\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "# Edit names if needed based on files in your folder.\n",
    "quick_pair_plot(panels, \"panel_data_s11\", \"panel_data_s12\", firm_id=1)\n",
    "quick_pair_plot(panels, \"panel_data_s21\", \"panel_data_s22\", firm_id=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}